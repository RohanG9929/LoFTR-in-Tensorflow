{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Running LoFTR in Tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-11-18 16:39:12.872889: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.10.0\n",
      "2.10.0\n"
     ]
    }
   ],
   "source": [
    "import cv2 as cv\n",
    "import tensorflow as tf\n",
    "import h5py\n",
    "print(tf.__version__)\n",
    "print(tf.keras.__version__)\n",
    "config = {'backbone_type': 'ResNetFPN', \n",
    "            'resolution': (8, 2), \n",
    "            'fine_window_size': 5, \n",
    "            'fine_concat_coarse_feat': True, \n",
    "            'resnetfpn': {'initial_dim': 128, 'block_dims': [128,196,256]}, \n",
    "            'coarse': {'d_model': 256, 'd_ffn': 256, 'nhead': 8, 'layer_names': ['self', 'cross', 'self', 'cross', 'self', 'cross', 'self', 'cross'], 'attention': 'linear', 'temp_bug_fix': True}, \n",
    "            'match_coarse': {'thr': 0.2, 'border_rm': 2, 'match_type': 'dual_softmax', 'dsmax_temperature': 0.1, 'skh_iters': 3, 'skh_init_bin_score': 1.0, 'skh_prefilter': True, 'train_coarse_percent': 0.4, 'train_pad_num_gt_min': 200}, \n",
    "            'fine': {'d_model': 128, 'd_ffn': 128, 'nhead': 8, 'layer_names': ['self','cross'], 'attention': 'linear'}}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-11-18 16:39:23.127357: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Course output is (1, 4800, 256) (1, 4800, 256)\n",
      "No matches found in coarse-level.\n",
      "{'image0': <tf.Tensor: shape=(1, 1, 480, 640), dtype=float32, numpy=\n",
      "array([[[[0., 0., 0., ..., 0., 0., 0.],\n",
      "         [0., 0., 0., ..., 0., 0., 0.],\n",
      "         [0., 0., 0., ..., 0., 0., 0.],\n",
      "         ...,\n",
      "         [0., 0., 0., ..., 0., 0., 0.],\n",
      "         [0., 0., 0., ..., 0., 0., 0.],\n",
      "         [0., 0., 0., ..., 0., 0., 0.]]]], dtype=float32)>, 'image1': <tf.Tensor: shape=(1, 1, 480, 640), dtype=float32, numpy=\n",
      "array([[[[0., 0., 0., ..., 0., 0., 0.],\n",
      "         [0., 0., 0., ..., 0., 0., 0.],\n",
      "         [0., 0., 0., ..., 0., 0., 0.],\n",
      "         ...,\n",
      "         [0., 0., 0., ..., 0., 0., 0.],\n",
      "         [0., 0., 0., ..., 0., 0., 0.],\n",
      "         [0., 0., 0., ..., 0., 0., 0.]]]], dtype=float32)>, 'bs': 1, 'hw0_i': TensorShape([480, 640]), 'hw1_i': TensorShape([480, 640]), 'hw0_c': TensorShape([60, 80]), 'hw1_c': TensorShape([60, 80]), 'hw0_f': TensorShape([240, 320]), 'hw1_f': TensorShape([240, 320]), 'conf_matrix': <tf.Tensor: shape=(1, 4800, 4800), dtype=float32, numpy=\n",
      "array([[[4.4665015e-08, 4.6396494e-08, 4.5851159e-08, ...,\n",
      "         3.7189913e-08, 3.9021312e-08, 4.2467807e-08],\n",
      "        [4.4476529e-08, 4.6949747e-08, 4.6356156e-08, ...,\n",
      "         3.8172395e-08, 4.0058904e-08, 4.3206313e-08],\n",
      "        [4.3937725e-08, 4.6344898e-08, 4.5795982e-08, ...,\n",
      "         3.7754869e-08, 3.9628002e-08, 4.2749374e-08],\n",
      "        ...,\n",
      "        [3.9772434e-08, 4.1816563e-08, 4.1351552e-08, ...,\n",
      "         3.7603471e-08, 3.9061081e-08, 4.1299462e-08],\n",
      "        [4.1042497e-08, 4.3121620e-08, 4.2643400e-08, ...,\n",
      "         3.7853930e-08, 3.9542662e-08, 4.2031886e-08],\n",
      "        [4.1516859e-08, 4.3491077e-08, 4.3021231e-08, ...,\n",
      "         3.7470681e-08, 3.9181764e-08, 4.1930100e-08]]], dtype=float32)>, 'b_ids': <tf.Tensor: shape=(0,), dtype=int64, numpy=array([], dtype=int64)>, 'i_ids': <tf.Tensor: shape=(0,), dtype=int64, numpy=array([], dtype=int64)>, 'j_ids': <tf.Tensor: shape=(0,), dtype=float64, numpy=array([], dtype=float64)>, 'gt_mask': <tf.Tensor: shape=(0,), dtype=bool, numpy=array([], dtype=bool)>, 'm_bids': <tf.Tensor: shape=(0,), dtype=int64, numpy=array([], dtype=int64)>, 'mkpts0_c': <tf.Tensor: shape=(0, 2), dtype=float64, numpy=array([], shape=(0, 2), dtype=float64)>, 'mkpts1_c': <tf.Tensor: shape=(0, 2), dtype=float64, numpy=array([], shape=(0, 2), dtype=float64)>, 'mconf': <tf.Tensor: shape=(0,), dtype=float64, numpy=array([], dtype=float64)>, 'W': 5, 'expec_f': <tf.Tensor: shape=(0, 3), dtype=float32, numpy=array([], shape=(0, 3), dtype=float32)>, 'mkpts0_f': <tf.Tensor: shape=(0, 2), dtype=float64, numpy=array([], shape=(0, 2), dtype=float64)>, 'mkpts1_f': <tf.Tensor: shape=(0, 2), dtype=float64, numpy=array([], shape=(0, 2), dtype=float64)>}\n"
     ]
    }
   ],
   "source": [
    "from LoFTR_TF import LoFTR\n",
    "\n",
    "#Creating the matcher \n",
    "matcher = LoFTR(config)\n",
    "\n",
    "\n",
    "#loading in the images for the current batch\n",
    "img0_pth = \"scene0738_00_frame-000885.jpg\"\n",
    "img1_pth = \"scene0738_00_frame-001065.jpg\"\n",
    "img0_raw = cv.imread(img0_pth, cv.IMREAD_GRAYSCALE)\n",
    "img1_raw = cv.imread(img1_pth, cv.IMREAD_GRAYSCALE)\n",
    "img0_raw = cv.resize(img0_raw, (640, 480))\n",
    "img1_raw = cv.resize(img1_raw, (640, 480))\n",
    "\n",
    "img0 = tf.convert_to_tensor(img0_raw)[None][None]/255\n",
    "img1 = tf.convert_to_tensor(img1_raw)[None][None]/255\n",
    "\n",
    "data = {'image0': img0, 'image1': img1}\n",
    "\n",
    "#Calling the matcher on the current batch\n",
    "updata = matcher(data)\n",
    "\n",
    "print(updata)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = {'LOFTR': \n",
    "\n",
    "{'BACKBONE_TYPE': 'ResNetFPN', 'RESOLUTION': (8, 2), 'FINE_WINDOW_SIZE': 5, 'FINE_CONCAT_COARSE_FEAT': True, \n",
    "    'RESNETFPN': {'INITIAL_DIM': 128, 'BLOCK_DIMS': [128, 196, 256]}, \n",
    "'COARSE': {'D_MODEL': 256, 'D_FFN': 256, 'NHEAD': 8, 'LAYER_NAMES': ['self', 'cross', 'self', 'cross', 'self', 'cross', 'self', 'cross'], 'ATTENTION': 'linear', 'TEMP_BUG_FIX': True}, \n",
    "'MATCH_COARSE': {'THR': 0.2, 'BORDER_RM': 2, 'MATCH_TYPE': 'dual_softmax', 'DSMAX_TEMPERATURE': 0.1, 'SKH_ITERS': 3, 'SKH_INIT_BIN_SCORE': 1.0, 'SKH_PREFILTER': False, 'TRAIN_COARSE_PERCENT': 0.2, 'TRAIN_PAD_NUM_GT_MIN': 200, 'SPARSE_SPVS': True},\n",
    "'FINE': {'D_MODEL': 128, 'D_FFN': 128, 'NHEAD': 8, 'LAYER_NAMES': ['self', 'cross'], 'ATTENTION': 'linear'}, \n",
    "'LOSS': {'COARSE_TYPE': 'focal', 'COARSE_WEIGHT': 1.0, 'FOCAL_ALPHA': 0.25, 'FOCAL_GAMMA': 2.0, 'POS_WEIGHT': 1.0, 'NEG_WEIGHT': 1.0, 'FINE_TYPE': 'l2_with_std', 'FINE_WEIGHT': 1.0, 'FINE_CORRECT_THR': 1.0}\n",
    "}, \n",
    "\n",
    "'DATASET': {'TRAINVAL_DATA_SOURCE': None, 'TRAIN_DATA_ROOT': None, 'TRAIN_POSE_ROOT': None, 'TRAIN_NPZ_ROOT': None, 'TRAIN_LIST_PATH': None, 'TRAIN_INTRINSIC_PATH': None, 'VAL_DATA_ROOT': None, 'VAL_POSE_ROOT': None, 'VAL_NPZ_ROOT': None, 'VAL_LIST_PATH': None, 'VAL_INTRINSIC_PATH': None, 'TEST_DATA_SOURCE': None, 'TEST_DATA_ROOT': None, 'TEST_POSE_ROOT': None, 'TEST_NPZ_ROOT': None, 'TEST_LIST_PATH': None, 'TEST_INTRINSIC_PATH': None, 'MIN_OVERLAP_SCORE_TRAIN': 0.4, 'MIN_OVERLAP_SCORE_TEST': 0.0, 'AUGMENTATION_TYPE': None, 'MGDPT_IMG_RESIZE': 640, 'MGDPT_IMG_PAD': True, 'MGDPT_DEPTH_PAD': True, 'MGDPT_DF': 8\n",
    "}, \n",
    "'TRAINER': {'WORLD_SIZE': 1, 'CANONICAL_BS': 64, 'CANONICAL_LR': 0.006, 'SCALING': None, 'FIND_LR': False, 'OPTIMIZER': 'adamw', 'TRUE_LR': None, 'ADAM_DECAY': 0.0, 'ADAMW_DECAY': 0.1, 'WARMUP_TYPE': 'linear', 'WARMUP_RATIO': 0.0, 'WARMUP_STEP': 4800, 'SCHEDULER': 'MultiStepLR', 'SCHEDULER_INTERVAL': 'epoch', 'MSLR_MILESTONES': [3, 6, 9, 12], 'MSLR_GAMMA': 0.5, 'COSA_TMAX': 30, 'ELR_GAMMA': 0.999992, 'ENABLE_PLOTTING': True, 'N_VAL_PAIRS_TO_PLOT': 32, 'PLOT_MODE': 'evaluation', 'PLOT_MATCHES_ALPHA': 'dynamic', 'EPI_ERR_THR': 0.0005, 'POSE_GEO_MODEL': 'E', 'POSE_ESTIMATION_METHOD': 'RANSAC', 'RANSAC_PIXEL_THR': 0.5, 'RANSAC_CONF': 0.99999, 'RANSAC_MAX_ITERS': 10000, 'USE_MAGSACPP': False, 'DATA_SAMPLER': 'scene_balance', 'N_SAMPLES_PER_SUBSET': 200, 'SB_SUBSET_SAMPLE_REPLACEMENT': True, 'SB_SUBSET_SHUFFLE': True, 'SB_REPEAT': 1, 'RDM_REPLACEMENT': True, 'RDM_NUM_SAMPLES': None, 'GRADIENT_CLIPPING': 0.5, 'SEED': 66\n",
    "}\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (1562246599.py, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  Input \u001b[0;32mIn [16]\u001b[0;36m\u001b[0m\n\u001b[0;31m    _config = {'loftr': {'backbone_type': 'ResNetFPN', 'resolution': (...), 'fine_window_size': 5, 'fine_concat_coarse_feat': True, 'resnetfpn': {...}, 'coarse': {...}, 'match_coarse': {...}, 'fine': {...}, 'loss': {...}}, 'dataset': {'trainval_data_source': 'ScanNet', 'train_data_root': 'data/scannet/train', 'train_pose_root': None, 'train_npz_root': 'data/scannet/index/s...data/train', 'train_list_path': 'data/scannet/index/s...et_all.txt', 'train_intrinsic_path': 'data/scannet/index/i...insics.npz', 'val_data_root': 'data/scannet/test', 'val_pose_root': None, 'val_npz_root': 'assets/scannet_test_1500', ...}, 'trainer': {'world_size': 4, 'canonical_bs': 64, 'canonical_lr': 0.006, 'scaling': 0.0625, 'find_lr': False, 'optimizer': 'adamw', 'true_lr': 0.000375, 'adam_decay': 0.0, 'adamw_decay': 0.1, ...}}\u001b[0m\n\u001b[0m                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "_config = {'loftr': {'backbone_type': 'ResNetFPN', 'resolution': (...), 'fine_window_size': 5, 'fine_concat_coarse_feat': True, 'resnetfpn': {...}, 'coarse': {...}, 'match_coarse': {...}, 'fine': {...}, 'loss': {...}}, 'dataset': {'trainval_data_source': 'ScanNet', 'train_data_root': 'data/scannet/train', 'train_pose_root': None, 'train_npz_root': 'data/scannet/index/s...data/train', 'train_list_path': 'data/scannet/index/s...et_all.txt', 'train_intrinsic_path': 'data/scannet/index/i...insics.npz', 'val_data_root': 'data/scannet/test', 'val_pose_root': None, 'val_npz_root': 'assets/scannet_test_1500', ...}, 'trainer': {'world_size': 4, 'canonical_bs': 64, 'canonical_lr': 0.006, 'scaling': 0.0625, 'find_lr': False, 'optimizer': 'adamw', 'true_lr': 0.000375, 'adam_decay': 0.0, 'adamw_decay': 0.1, ...}}\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "438126918821fe50c93f3db2c4763d5821f8338880c78e72f06f874d5164356b"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
